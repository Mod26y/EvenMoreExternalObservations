Original Article: https://www.bleepingcomputer.com/news/artificial-intelligence/x-faces-gdpr-complaints-for-unauthorized-use-of-data-for-ai-training/

### 1) What Happened

European privacy advocate NOYB has filed nine GDPR complaints against X for allegedly using the personal data of over 60 million European users without their consent to train its large language model, Grok. NOYB claims that X did not inform users or seek their consent as required under GDPR regulations. The unauthorized use of the data was noticed when a user identified a setting allowing Grok to use personal interactions and inputs for training purposes. Ireland's Data Protection Commissioner intervened, leading X to suspend processing data until September, but NOYB deemed these actions insufficient and filed multiple GDPR violation complaints.

### 2) Why it Matters

This situation underscores the critical importance of transparency and user consent in data processing, especially under stringent GDPR regulations. Unauthorized use of personal data for AI training not only breaches legal compliance but also undermines user trust and harbors potential for significant financial penalties. For large-scale organizations, such privacy violations can have broader implications, leading to regulatory scrutiny and public backlash. Furthermore, this underscores the complex compliance landscape for companies operating in multiple jurisdictions with varying data protection laws.

### 3) What Actions Should Be Taken

Organizations should conduct an immediate compliance audit to ensure that all data processing activities align with GDPR requirements. Transparent policies and user consent mechanisms need to be in place before using personal data for any secondary purposes like AI training. It's essential to enhance internal oversight and collaboration with legal teams to regularly review data handling practices. Developing a clear and accessible communication channel for users to understand how their data is used and to opt-out if desired will be crucial. Additionally, implementing robust data anonymization techniques can mitigate risks associated with handling personal data in AI training models.