Original Article: https://www.bleepingcomputer.com/news/artificial-intelligence/chatgpt-o3-api-80-percent-price-drop-has-no-impact-on-performance/

**1) What happened:** OpenAI announced a significant 80% price reduction for its ChatGPT o3 API model, reducing input costs to $2 per million tokens and output costs to $8 per million tokens. The company optimized the inference stack, ensuring no performance degradation despite the price cut. Independent benchmarks from the ARC Prize community verified the modelâ€™s unchanged performance. OpenAI also introduced the o3-pro model in the API, which leverages more computational power for enhanced results.

**2) Why it matters:** The price reduction makes the ChatGPT o3 API more accessible, potentially encouraging broader adoption of AI technologies across various sectors by reducing barriers to entry. As organizations increasingly integrate artificial intelligence into operations, the cost-efficiency ensures that quality and performance are maintained without inflating budgets. This can enable more innovative tool development, streamline processes, and foster productivity enhancements, especially for smaller entities that might previously find such technology cost-prohibitive.

**3) What actions should be taken:** Organizations using AI technologies should explore the opportunity to integrate or upgrade to ChatGPT o3 API given its new cost-effectiveness without performance compromise. They should assess current AI expenditures and consider reallocating budgets for maximum efficiency and innovation. Continuous monitoring of performance metrics can ensure the optimized model continues to meet organizational needs. Information security teams should remain vigilant on emerging AI dependencies, understanding potential security implications and ensuring robust data privacy practices remain in place.