Original Article: https://www.bleepingcomputer.com/news/security/ai-hallucinated-code-dependencies-become-new-supply-chain-risk/

1) What happened: The article outlines a new type of supply chain attack called "slopsquatting," emerging from generative AI's tendency to hallucinate non-existent package names. This vulnerability arises when AI models generate coding examples, leading to developers accidentally incorporating these non-existent packages into their projects. Threat actors may exploit this by creating malicious packages with the AI-hallucinated names on platforms like PyPI and npm. The study found a significant portion of AI-generated package recommendations do not exist, presenting attackers with a new avenue for supply chain exploitation due to the repeatable and predictable nature of these hallucinations.

2) Why it matters: The emergence of slopsquatting highlights a novel risk associated with using AI in development, affecting the software supply chain's integrity. The high rate of non-existent package recommendations from AI increases the likelihood of developers inadvertently incorporating malicious or incorrect packages into their projects, potentially leading to security vulnerabilities. Given the substantial usage of AI-assisted tools in coding, this risk could be far-reaching, making it crucial for development and security teams to be aware and take preemptive steps to mitigate potential threats to their software ecosystems.

3) What actions should be taken: To manage this risk, developers should manually verify package names against known, existing libraries when working with AI-generated code. Implementing dependency scanners, lockfiles, and hash verification can secure the software supply chain by ensuring packages match trusted versions. Reducing AI model "temperature" settings might decrease hallucination occurrences, further minimizing risks. Additionally, testing AI-generated code in isolated environments before deployment will help prevent potential exploitation. Education on the possibility of slopsquatting and integrating security best practices in AI-assisted development workflows will be pivotal in safeguarding against this emerging threat.