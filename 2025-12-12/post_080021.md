Original Article: https://www.bleepingcomputer.com/news/artificial-intelligence/brave-browser-starts-testing-agentic-ai-mode-for-automated-tasks/

**1) What happened:**

The Brave browser has initiated a test phase for its new AI-driven agentic browsing mode, featuring Leo as its privacy-respecting AI assistant. This mode assists users with tasks such as web research, product comparisons, and news summarization. Currently, it is available via the Brave Nightly build, functioning independently from user-sensitive data by default. To mitigate security risks associated with AI, such as prompt injection attacks, the mode operates in a separate profile with limitations on accessing specific resources and invokes an alignment checker to ensure AI actions align with user intentions.

**2) Why it matters:**

The introduction of agentic AI browsing represents a significant development in enhancing user browsing experiences through automation while prioritizing privacy. By isolating AI operations and implementing protections against AI vulnerabilities, Brave sets a precedent for balancing innovation with cybersecurity. This initiative introduces necessary discourse around AI's potential risks when integrated into widely used platforms, emphasizing the need for secure deployment practices. For users and organizations, it highlights the evolving landscape of web-based automated tasks and underscores the importance of ensuring these advancements do not compromise data integrity or privacy.

**3) What actions should be taken:**

Organizations using Brave or similar AI-enabled tools should closely monitor developments in AI and automation integration in web browsers. They can engage with testing programs like Brave's to better understand potential benefits and risks. Conducting risk assessments focusing on AI's influence on privacy and security is essential, considering employing mitigations like those demonstrated by Brave. For comprehensive protection, entities should consider adopting practices like isolated AI environments and continuous monitoring for AI actions. Security teams may also explore minimizing dependence on such features for critical operations until more robust security assurances are established.