Original Article: https://www.darkreading.com/cyber-risk/4-ways-fight-ai-based-fraud

**What happened:**  
The commentary discusses the growing threat of AI-based fraud, particularly through the use of generative AI and deepfakes by cybercriminals. These tools make fraudulent activities more convincing and widespread. Notable incidents include a $25 million scam via a deepfake video call and the misuse of biometric data for identity fraud. Enterprises face a significant challenge as AI-driven tactics compromise traditional security measures. The frequency and sophistication of such attacks are on the rise, with estimates predicting a substantial impact on enterprise security systems by 2026.

**Why it matters:**  
The increasing prevalence of AI-based fraud represents a critical threat to both individuals and organizations, with the potential to cause significant financial and reputational damage. As these AI techniques become more sophisticated, traditional identity verification systems are rendered less reliable. The convergence of AI with existing social engineering tactics amplifies the threat landscape, demanding urgent attention to defense mechanisms. This trend signals a pressing need for innovation in cybersecurity measures, given the rapid evolution of attack strategies that leverage AI technologies to exploit systemic vulnerabilities.

**Actions to be taken:**  
Organizations should enhance their cybersecurity infrastructure by implementing AI analytics that mirror those used by threat actors, thus aiding in the detection of anomalies and potential breaches. They need to focus on improving data quality and develop a robust understanding of normal network behavior to efficiently identify anomalies. Additionally, adopting a zero-trust architecture can bolster defenses against AI-powered threats. Telemetry data, specifically from deep packet inspection, can serve as a reliable foundation for AI defenses, providing real-time insights to preemptively address vulnerabilities and mitigate AI-driven fraud attempts.