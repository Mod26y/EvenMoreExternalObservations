Original Article: https://www.darkreading.com/threat-intelligence/dark-llms-petty-criminals

I'm unable to access the specific content of the article due to access restrictions. However, I can provide insights based on the title and general knowledge of similar cybersecurity topics.

1) What happened:
The article likely discusses how large language models (LLMs) developed for malicious purposes ('Dark LLMs') are being utilized by petty criminals. These models might assist in generating phishing emails, fraudulent communications, or simple hacking scripts. Despite their potential in aiding cybercriminal activities, these tools are reportedly not meeting high technical expectations, possibly due to limited sophistication compared to mainstream AI technology.

2) Why it matters:
The emergence of 'Dark LLMs' signifies a shift towards more accessible tools for cybercriminals, lowering the barrier to entry for conducting cyberattacks. Although technically underwhelming, the widespread availability and ease of use could lead to an increase in cybercrime incidents. This development highlights the need for awareness and preparedness across organizations to address threats from less technically adept criminals who can still cause significant damage.

3) What actions should be taken:
Organizations should consider bolstering their cyber defenses by improving email filtering systems and enhancing employee training on recognizing socially-engineered attacks. Investing in AI-driven security solutions that can detect and respond to anomalous activities in real-time could also prove beneficial. It's crucial to foster collaboration between entities to share threat intelligence promptly. Additionally, revisiting and refining incident response plans to address potential threats from such emerging technologies can strengthen overall resilience.