Original Article: https://www.darkreading.com/cloud-security/cyberattackers-ghostgpt-write-malicious-code

GhostGPT is an uncensored AI chatbot found recently on sale that is being used by cybercriminals for activities such as writing malware and creating phishing emails. It bypasses standard AI safeguards, making it easier for individuals with little technical expertise to perform malicious activities. Initially detected on a Telegram channel, GhostGPT offers pricing models from $50 for a week to $300 for three months, appealing to those looking for anonymity, as it claims not to keep usage logs.

The introduction of GhostGPT signifies a significant threat by making it easier for cybercriminals to produce dangerous software and execute scams. Unlike traditional AI platforms that block harmful content, GhostGPT's lack of restrictions and anonymity make it attractive to criminals, lowering the barrier for entry into cybercrime markets. This evolution of AI misuse emphasizes the growing challenge for security teams working to prevent such technologies from being abused to facilitate illicit actions.

To respond to the challenges posed by GhostGPT, organizations could improve awareness and training on AI-enabled threats, ensuring that employees can recognize and react to phishing attempts. Regular updates to security policies to anticipate such technologies and potential exploits may help mitigate risks. Additionally, leveraging advanced AI security tools might enhance detection and response capabilities against threats facilitated by rogue AI chatbots. Intelligence on these evolving threats can guide more proactive protection strategies.